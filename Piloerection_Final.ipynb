{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMfAQUk03XcLKze6fWpowU7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeoTU911/Piloerection/blob/main/Piloerection_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. DATA IMPORT\n",
        "\n",
        "  1.1 Import code from github\n",
        "\n",
        "  1.2 Mount Google drive and copy the video data of Google drive to Colab local disk"
      ],
      "metadata": {
        "id": "GBHAjCv_AA4E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7BJm0X0sA8K",
        "outputId": "995888a7-9bd9-4019-9840-6a1a41d8f85b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Piloerection'...\n",
            "remote: Enumerating objects: 221, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 221 (delta 2), reused 0 (delta 0), pack-reused 213\u001b[K\n",
            "Receiving objects: 100% (221/221), 110.97 KiB | 848.00 KiB/s, done.\n",
            "Resolving deltas: 100% (117/117), done.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# import code files on Github\n",
        "!git clone https://github.com/LeoTU911/Piloerection\n",
        "\n",
        "# import dataset from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "8_BMt-JtEocu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create local dir to store data\n",
        "# Training dir structure\n",
        "!mkdir -p /content/data/train/\n",
        "!mkdir -p /content/data/train/video/\n",
        "!mkdir -p /content/data/train/video/1-grid_videos\n",
        "!mkdir -p /content/data/train/video/4-grid_videos\n",
        "!mkdir -p /content/data/train/file/\n",
        "!mkdir -p /content/data/train/file/1-grid/\n",
        "!mkdir -p /content/data/train/file/4-grid/\n",
        "\n",
        "# copy\n",
        "!cp /content/drive/MyDrive/Piloerection/trainData/video/1-grid_videos/* /content/data/train/video/1-grid_videos\n",
        "!cp /content/drive/MyDrive/Piloerection/trainData/video/4-grid_videos/* /content/data/train/video/4-grid_videos\n",
        "!cp /content/drive/MyDrive/Piloerection/trainData/file/1-grid/* /content/data/train/file/1-grid/\n",
        "!cp /content/drive/MyDrive/Piloerection/trainData/file/4-grid/* /content/data/train/file/4-grid/"
      ],
      "metadata": {
        "id": "ajutN8WyAqx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction"
      ],
      "metadata": {
        "id": "PxTbPM1kEswN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create local dir to store data\n",
        "# prediction dir structure\n",
        "!mkdir -p /content/data/test/\n",
        "!mkdir -p /content/data/test/video/\n",
        "!mkdir -p /content/data/test/video/1-grid_videos\n",
        "!mkdir -p /content/data/test/video/4-grid_videos\n",
        "!mkdir -p /content/data/test/file/\n",
        "!mkdir -p /content/data/test/file/1-grid/\n",
        "!mkdir -p /content/data/test/file/4-grid/\n",
        "\n",
        "# copy\n",
        "!cp /content/drive/MyDrive/Piloerection/testData/video/1-grid_videos/* /content/data/test/video/1-grid_videos\n",
        "!cp /content/drive/MyDrive/Piloerection/testData/video/4-grid_videos/* /content/data/test/video/4-grid_videos\n",
        "!cp /content/drive/MyDrive/Piloerection/testData/file/1-grid/* /content/data/test/file/1-grid/\n",
        "!cp /content/drive/MyDrive/Piloerection/testData/file/4-grid/* /content/data/test/file/4-grid/"
      ],
      "metadata": {
        "id": "ayUajOXeD4Kq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1df9a629-47bb-4b5d-ec82-5399800d289c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: target '/content/data/train/test/file/1-grid/' is not a directory\n",
            "cp: target '/content/data/train/test/file/4-grid/' is not a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Piloerection/testData/file/1-grid/* /content/data/test/file/1-grid/\n",
        "!cp /content/drive/MyDrive/Piloerection/testData/file/4-grid/* /content/data/test/file/4-grid/"
      ],
      "metadata": {
        "id": "dzhRCp0ncrsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. DATA PREPROCESSING PART\n",
        "\n",
        "  2.1 Convert video frame to picture\n",
        "\n",
        "  2.2 Frame image preprocessing: denoising, enhancement, changing image size, classification"
      ],
      "metadata": {
        "id": "XmNGprEdEGtM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "uQk8J2pUFEBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# video to images\n",
        "!python /content/Piloerection/linux/video2Img.py\\\n",
        "  --mode='training'\\\n",
        "  --file_Path='/content/data/train/video/'\n",
        "\n",
        "# images pre-processing\n",
        "!python /content/Piloerection/linux/imgPreprocessing.py\\\n",
        "  --mode='training'\\\n",
        "  --frameFile_Path='/content/data/train/frameImage/'\\\n",
        "  --labelFile_Path='/content/data/train/file/'"
      ],
      "metadata": {
        "id": "t1wY17lFEhuw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cacb9b48-fe06-4c17-bf6d-1bccbf7b67e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data/train/video/frameImage created successfully!\n",
            "Videos to be converted:['039.wmv', '036.wmv', '021.wmv', '043.wmv', '054.wmv', '037.wmv', '051.wmv', '032.wmv', '027.wmv', '012.wmv', '046.wmv', '014.wmv', '057.wmv', '028.wmv', '040.wmv', '041.wmv', '024.wmv', '026.wmv', '017.wmv', '034.wmv', '052.wmv', '049.wmv', '022.wmv', '018.wmv', '058.wmv', '023.wmv', '055.wmv', '048.wmv', '035.wmv', '033.wmv', '045.wmv', '038.wmv', '050.wmv', '015.wmv', '056.wmv', '042.wmv', '047.wmv', '044.wmv', '025.wmv', '013.wmv', '019.wmv', '059.wmv', '053.wmv', '030.wmv', '031.wmv', '016.wmv', '029.wmv']\n",
            "039.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "49 pictures saved in /content/data/train/video/frameImage\n",
            "036.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "47 pictures saved in /content/data/train/video/frameImage\n",
            "021.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "60 pictures saved in /content/data/train/video/frameImage\n",
            "043.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "25 pictures saved in /content/data/train/video/frameImage\n",
            "054.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "30 pictures saved in /content/data/train/video/frameImage\n",
            "037.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "28 pictures saved in /content/data/train/video/frameImage\n",
            "051.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "26 pictures saved in /content/data/train/video/frameImage\n",
            "032.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "33 pictures saved in /content/data/train/video/frameImage\n",
            "027.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "39 pictures saved in /content/data/train/video/frameImage\n",
            "012.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "59 pictures saved in /content/data/train/video/frameImage\n",
            "046.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "38 pictures saved in /content/data/train/video/frameImage\n",
            "014.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "60 pictures saved in /content/data/train/video/frameImage\n",
            "057.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "33 pictures saved in /content/data/train/video/frameImage\n",
            "028.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "26 pictures saved in /content/data/train/video/frameImage\n",
            "040.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "41 pictures saved in /content/data/train/video/frameImage\n",
            "041.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "42 pictures saved in /content/data/train/video/frameImage\n",
            "024.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "27 pictures saved in /content/data/train/video/frameImage\n",
            "026.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "23 pictures saved in /content/data/train/video/frameImage\n",
            "017.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "43 pictures saved in /content/data/train/video/frameImage\n",
            "034.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "48 pictures saved in /content/data/train/video/frameImage\n",
            "052.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "28 pictures saved in /content/data/train/video/frameImage\n",
            "049.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "42 pictures saved in /content/data/train/video/frameImage\n",
            "022.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "25 pictures saved in /content/data/train/video/frameImage\n",
            "018.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "54 pictures saved in /content/data/train/video/frameImage\n",
            "058.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "35 pictures saved in /content/data/train/video/frameImage\n",
            "023.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "16 pictures saved in /content/data/train/video/frameImage\n",
            "055.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "39 pictures saved in /content/data/train/video/frameImage\n",
            "048.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "45 pictures saved in /content/data/train/video/frameImage\n",
            "035.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "47 pictures saved in /content/data/train/video/frameImage\n",
            "033.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "25 pictures saved in /content/data/train/video/frameImage\n",
            "045.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "29 pictures saved in /content/data/train/video/frameImage\n",
            "038.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "46 pictures saved in /content/data/train/video/frameImage\n",
            "050.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "42 pictures saved in /content/data/train/video/frameImage\n",
            "015.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "62 pictures saved in /content/data/train/video/frameImage\n",
            "056.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "35 pictures saved in /content/data/train/video/frameImage\n",
            "042.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "45 pictures saved in /content/data/train/video/frameImage\n",
            "047.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "44 pictures saved in /content/data/train/video/frameImage\n",
            "044.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "31 pictures saved in /content/data/train/video/frameImage\n",
            "025.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "27 pictures saved in /content/data/train/video/frameImage\n",
            "013.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "63 pictures saved in /content/data/train/video/frameImage\n",
            "019.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "58 pictures saved in /content/data/train/video/frameImage\n",
            "059.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "47 pictures saved in /content/data/train/video/frameImage\n",
            "053.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "56 pictures saved in /content/data/train/video/frameImage\n",
            "030.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "47 pictures saved in /content/data/train/video/frameImage\n",
            "031.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "57 pictures saved in /content/data/train/video/frameImage\n",
            "016.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "51 pictures saved in /content/data/train/video/frameImage\n",
            "029.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 640 x 360\n",
            "28 pictures saved in /content/data/train/video/frameImage\n",
            "Videos to be converted:['064.wmv', '063.wmv', '066.wmv', '068.wmv', '062.wmv', '065.wmv', '067.wmv']\n",
            "064.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 1920 x 1080\n",
            "216 pictures saved in /content/data/train/video/frameImage\n",
            "063.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 1920 x 1080\n",
            "204 pictures saved in /content/data/train/video/frameImage\n",
            "066.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 1920 x 1080\n",
            "268 pictures saved in /content/data/train/video/frameImage\n",
            "068.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 1920 x 1080\n",
            "220 pictures saved in /content/data/train/video/frameImage\n",
            "062.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 1920 x 1080\n",
            "208 pictures saved in /content/data/train/video/frameImage\n",
            "065.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 1920 x 1080\n",
            "220 pictures saved in /content/data/train/video/frameImage\n",
            "067.wmv\n",
            "frame rate is： 1000.0\n",
            "resolution is： 1920 x 1080\n",
            "212 pictures saved in /content/data/train/video/frameImage\n",
            "video to frame image finished, images saved in /content/data/train/video/frameImage, time spent: 10904.1873s\n",
            "python3: can't open file '/content/Piloerection/linux/imgPreprocessing.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zip file\n",
        "!zip -r '/content/data/train/\"trainFile.zip\"' '/content/data/train/frameImage/*'"
      ],
      "metadata": {
        "id": "6pVVVOxSLH25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction"
      ],
      "metadata": {
        "id": "_BzArIUKGht1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# video to images\n",
        "!python /content/Piloerection/video2Img.py\\\n",
        "  --mode='prediction'\\\n",
        "  --file_Path='/content/data/test/video/'\n",
        "\n",
        "# images pre-processing\n",
        "!python /content/Piloerection/imgPreprocessing.py\\\n",
        "  --mode='prediction'\\\n",
        "  --frameFile_Path='/content/data/test/frameImage/'"
      ],
      "metadata": {
        "id": "nfiMD-NpGjTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zip file\n",
        "!zip -r '/content/data/test/\"testFile.zip\"' '/content/data/test/frameImage/*'"
      ],
      "metadata": {
        "id": "cg34l6IdLLg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TRAINING PART ###"
      ],
      "metadata": {
        "id": "utcnuhaYtv6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare for training\n",
        "# copy files to Colab local disk\n",
        "!mkdir -p /content/data/train/upload/\n",
        "!cp /content/drive/MyDrive/Piloerection/trainData/0725/*.zip /content/data/train/upload/\n",
        "# create local directory\n",
        "!mkdir -p /content/data/train/frameImage/\n",
        "!mkdir -p /content/data/train/frameImage/no/\n",
        "!mkdir -p /content/data/train/frameImage/small/\n",
        "!mkdir -p /content/data/train/frameImage/large/\n",
        "\n",
        "!unzip -uq '/content/data/train/upload/large.zip' -d '/content/data/train/frameImage/large/'\n",
        "!unzip -uq '/content/data/train/upload/small_batch1.zip' -d '/content/data/train/frameImage/small/'\n",
        "!unzip -uq '/content/data/train/upload/small_batch2.zip' -d '/content/data/train/frameImage/small/'\n",
        "!unzip -uq '/content/data/train/upload/small_batch3.zip' -d '/content/data/train/frameImage/small/'\n",
        "!unzip -uq '/content/data/train/upload/no_batch1.zip' -d '/content/data/train/frameImage/no/'\n",
        "!unzip -uq '/content/data/train/upload/no_batch2.zip' -d '/content/data/train/frameImage/no/'\n",
        "!unzip -uq '/content/data/train/upload/no_batch3.zip' -d '/content/data/train/frameImage/no/'\n",
        "!unzip -uq '/content/data/train/upload/no_batch4.zip' -d '/content/data/train/frameImage/no/'\n",
        "!unzip -uq '/content/data/train/upload/no_batch5.zip' -d '/content/data/train/frameImage/no/'\n",
        "!unzip -uq '/content/data/train/upload/no_batch6.zip' -d '/content/data/train/frameImage/no/'\n",
        "!unzip -uq '/content/data/train/upload/no_batch7.zip' -d '/content/data/train/frameImage/no/'"
      ],
      "metadata": {
        "id": "h6iiSO-JwTHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Piloerection/vit_large-20.pth  /content/data/train/upload"
      ],
      "metadata": {
        "id": "3lo1_ryYsuNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Piloerection/train.py\\\n",
        " --data_path='/content/data/train/frameImage'\\\n",
        " --model_name='vgg16'\\\n",
        " --num_classes=3\\\n",
        " --weights=''\\\n",
        " --epochs=50\\\n",
        " --batch_size=128\\\n",
        " --save_best_weights='True'\\\n",
        " --optimizer='Adam'"
      ],
      "metadata": {
        "id": "9BgRTOPD4pyt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4437bdd7-97a1-452b-b31b-0cac11cf1ca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-03 14:43:10.117739: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-03 14:43:11.076934: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "183647 images were found in the dataset.\n",
            "146920 images for training.\n",
            "36727 images for validation.\n",
            "Using 2 dataloader workers every process\n",
            "train vgg16 model\n",
            "[train epoch 0] loss: 0.723, acc: 0.724: 100% 1148/1148 [11:09<00:00,  1.72it/s]\n",
            "[valid epoch 0] loss: 0.716, acc: 0.725: 100% 287/287 [02:18<00:00,  2.07it/s]\n",
            "[train epoch 1] loss: 0.717, acc: 0.725: 100% 1148/1148 [10:59<00:00,  1.74it/s]\n",
            "[valid epoch 1] loss: 0.715, acc: 0.725: 100% 287/287 [02:15<00:00,  2.12it/s]\n",
            "[train epoch 2] loss: 0.717, acc: 0.725: 100% 1148/1148 [10:50<00:00,  1.76it/s]\n",
            "[valid epoch 2] loss: 0.717, acc: 0.725: 100% 287/287 [02:10<00:00,  2.19it/s]\n",
            "[train epoch 3] loss: 0.717, acc: 0.725: 100% 1148/1148 [10:49<00:00,  1.77it/s]\n",
            "[valid epoch 3] loss: 0.716, acc: 0.725: 100% 287/287 [02:12<00:00,  2.17it/s]\n",
            "[train epoch 4] loss: 0.717, acc: 0.725: 100% 1148/1148 [10:48<00:00,  1.77it/s]\n",
            "[valid epoch 4] loss: 0.716, acc: 0.725: 100% 287/287 [02:12<00:00,  2.17it/s]\n",
            "[train epoch 5] loss: 0.716, acc: 0.725: 100% 1148/1148 [10:46<00:00,  1.78it/s]\n",
            "[valid epoch 5] loss: 0.715, acc: 0.725: 100% 287/287 [02:11<00:00,  2.19it/s]\n",
            "[train epoch 6] loss: 0.717, acc: 0.725: 100% 1148/1148 [10:47<00:00,  1.77it/s]\n",
            "[valid epoch 6] loss: 0.715, acc: 0.725: 100% 287/287 [02:12<00:00,  2.17it/s]\n",
            "[train epoch 7] loss: 0.716, acc: 0.725: 100% 1148/1148 [10:47<00:00,  1.77it/s]\n",
            "[valid epoch 7] loss: 0.716, acc: 0.725: 100% 287/287 [02:13<00:00,  2.14it/s]\n",
            "[train epoch 8] loss: 0.716, acc: 0.725: 100% 1148/1148 [10:47<00:00,  1.77it/s]\n",
            "[valid epoch 8] loss: 0.715, acc: 0.725: 100% 287/287 [02:13<00:00,  2.16it/s]\n",
            "[train epoch 9] loss: 0.716, acc: 0.725: 100% 1148/1148 [10:47<00:00,  1.77it/s]\n",
            "[valid epoch 9] loss: 0.715, acc: 0.725: 100% 287/287 [02:13<00:00,  2.16it/s]\n",
            "[train epoch 10] loss: 0.716, acc: 0.725: 100% 1148/1148 [10:49<00:00,  1.77it/s]\n",
            "[valid epoch 10] loss: 0.716, acc: 0.725: 100% 287/287 [02:13<00:00,  2.15it/s]\n",
            "[train epoch 11] loss: 0.716, acc: 0.725: 100% 1148/1148 [10:47<00:00,  1.77it/s]\n",
            "[valid epoch 11] loss: 0.715, acc: 0.725: 100% 287/287 [02:12<00:00,  2.16it/s]\n",
            "[train epoch 12] loss: 0.716, acc: 0.725: 100% 1148/1148 [10:48<00:00,  1.77it/s]\n",
            "[valid epoch 12] loss: 0.715, acc: 0.725: 100% 287/287 [02:11<00:00,  2.18it/s]\n",
            "[train epoch 13] loss: 0.716, acc: 0.725: 100% 1148/1148 [10:47<00:00,  1.77it/s]\n",
            "[valid epoch 13] loss: 0.715, acc: 0.725: 100% 287/287 [02:12<00:00,  2.17it/s]\n",
            "[train epoch 14] loss: 0.716, acc: 0.725: 100% 1148/1148 [10:49<00:00,  1.77it/s]\n",
            "[valid epoch 14] loss: 0.716, acc: 0.725: 100% 287/287 [02:11<00:00,  2.18it/s]\n",
            "[train epoch 15] loss: 0.716, acc: 0.725: 100% 1148/1148 [10:49<00:00,  1.77it/s]\n",
            "[valid epoch 15] loss: 0.716, acc: 0.725: 100% 287/287 [02:10<00:00,  2.20it/s]\n",
            "[train epoch 16] loss: 0.716, acc: 0.725: 100% 1148/1148 [10:47<00:00,  1.77it/s]\n",
            "[valid epoch 16] loss: 0.715, acc: 0.725: 100% 287/287 [02:10<00:00,  2.20it/s]\n",
            "[train epoch 17] loss: 0.716, acc: 0.725: 100% 1148/1148 [10:47<00:00,  1.77it/s]\n",
            "[valid epoch 17] loss: 0.715, acc: 0.725: 100% 287/287 [02:09<00:00,  2.22it/s]\n",
            "[train epoch 18] loss: 0.716, acc: 0.725: 100% 1148/1148 [10:43<00:00,  1.78it/s]\n",
            "[valid epoch 18] loss: 0.716, acc: 0.725: 100% 287/287 [02:08<00:00,  2.23it/s]\n",
            "[train epoch 19] loss: 0.716, acc: 0.725: 100% 1148/1148 [10:45<00:00,  1.78it/s]\n",
            "[valid epoch 19] loss: 0.716, acc: 0.725: 100% 287/287 [02:08<00:00,  2.23it/s]\n",
            "[train epoch 20] loss: 0.716, acc: 0.725: 100% 1148/1148 [10:44<00:00,  1.78it/s]\n",
            "[valid epoch 20] loss: 0.715, acc: 0.725: 100% 287/287 [02:11<00:00,  2.18it/s]\n",
            "[train epoch 21] loss: 0.716, acc: 0.725: 100% 1148/1148 [10:46<00:00,  1.78it/s]\n",
            "[valid epoch 21] loss: 0.715, acc: 0.725: 100% 287/287 [02:10<00:00,  2.21it/s]\n",
            "[train epoch 22] loss: 0.716, acc: 0.725: 100% 1148/1148 [10:46<00:00,  1.78it/s]\n",
            "[valid epoch 22] loss: 0.716, acc: 0.725: 100% 287/287 [02:08<00:00,  2.23it/s]\n",
            "[train epoch 23] loss: 0.716, acc: 0.725: 100% 1148/1148 [10:46<00:00,  1.77it/s]\n",
            "[valid epoch 23] loss: 0.715, acc: 0.725: 100% 287/287 [02:10<00:00,  2.20it/s]\n",
            "[train epoch 24] loss: 0.716, acc: 0.725: 100% 1148/1148 [10:46<00:00,  1.78it/s]\n",
            "[valid epoch 24] loss: 0.715, acc: 0.725: 100% 287/287 [02:10<00:00,  2.19it/s]\n",
            "[train epoch 25] loss: 0.716, acc: 0.725: 100% 1148/1148 [10:48<00:00,  1.77it/s]\n",
            "[valid epoch 25] loss: 0.715, acc: 0.725: 100% 287/287 [02:10<00:00,  2.20it/s]\n",
            "[train epoch 26] loss: 0.716, acc: 0.725: 100% 1148/1148 [10:48<00:00,  1.77it/s]\n",
            "[valid epoch 26] loss: 0.715, acc: 0.725: 100% 287/287 [02:10<00:00,  2.20it/s]\n",
            "[train epoch 27] loss: 0.716, acc: 0.725:  94% 1076/1148 [10:09<00:40,  1.77it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Piloerection/train.py\", line 201, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/Piloerection/train.py\", line 136, in main\n",
            "    train_loss, train_acc = train_one_epoch(model=model,\n",
            "  File \"/content/Piloerection/utils.py\", line 139, in train_one_epoch\n",
            "    pred = model(images.to(device))\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model's weights to google drive\n",
        "!cp /content/weights/vgg16-0.pth /content/drive/MyDrive/Piloerection\n",
        "\n",
        "#!cp /content/class_indices.json /content/drive/MyDrive/Piloerection"
      ],
      "metadata": {
        "id": "_rrejCiZ2-aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PREDICTION PART ###"
      ],
      "metadata": {
        "id": "Jm-Zaixlmtpg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction with single model"
      ],
      "metadata": {
        "id": "HLM_w2my9hN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare for test\n",
        "# copy test files to Colab local disk\n",
        "!mkdir -p /content/data/test/upload/\n",
        "!cp /content/drive/MyDrive/Piloerection/testData/test_0804.zip /content/data/test/upload/\n",
        "\n",
        "!unzip -uq '/content/data/test/upload/test_0804.zip' -d '/content/data/test/'\n",
        "\n",
        "# copy trained model weights to Colab local disk\n",
        "!mkdir -p /content/data/model\n",
        "!mkdir -p /content/data/model/weights\n",
        "# AlexNet\n",
        "!cp /content/drive/MyDrive/Piloerection/model/AlexNet/AlexNet-47_0729.pth /content/data/model/weights/\n",
        "# ViT Large\n",
        "!cp /content/drive/MyDrive/Piloerection/model/ViT/vit_large-20_0727.pth /content/data/model/weights\n",
        "# ViT base\n",
        "!cp /content/drive/MyDrive/Piloerection/model/ViT/vit_base-29_0726.pth /content/data/model/weights\n",
        "# VGG19\n",
        "!cp /content/drive/MyDrive/Piloerection/model/vgg/vgg19-0_0731.pth /content/data/model/weights/\n",
        "# VGG16\n",
        "!cp /content/drive/MyDrive/Piloerection/model/vgg/vgg16-0_0803.pth /content/data/model/weights/\n",
        "# ResNet101\n",
        "!cp /content/drive/MyDrive/Piloerection/model/ResNet/resnet101-43_0803.pth /content/data/model/weights/\n",
        "# ResNet50\n",
        "!cp /content/drive/MyDrive/Piloerection/model/ResNet/resnet50-45_0801.pth /content/data/model/weights/\n",
        "\n",
        "# copy class indices to Colab local disk\n",
        "!cp /content/drive/MyDrive/Piloerection/model/class_indices.json /content/data/model/\n",
        "# copy models' predict weights to Colab local disk\n",
        "#!cp /content/drive/MyDrive/Piloerection/model/model_weights.csv /content/data/model/"
      ],
      "metadata": {
        "id": "gOsnA5-bgNw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Piloerection/predict_SingleModel.py\\\n",
        " --data_path='/content/data/test/frameImage'\\\n",
        " --model_name='vgg19'\\\n",
        " --cal_acc='False'\\\n",
        " --label_path=''\\\n",
        " --save_path='/content/data/prediction/'\\\n",
        " --weights='/content/data/model/weights/vgg19-0_0731.pth'\\\n",
        " --class_indices='/content/data/model/class_indices.json'\\\n",
        " --num_classes=3"
      ],
      "metadata": {
        "id": "PNPNSZWumUn9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "924fa9ef-3095-467e-8d83-dc7cba32bb85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "now predict 111\n",
            "train vgg19 model\n",
            "Current Progress: 1/1440\n",
            "Time Spent of 1 Loop: 1.4686s\n",
            "Estimate Time Left: 00:35:13.352\n",
            "Current Progress: 101/1440\n",
            "Time Spent of 1 Loop: 0.0103s\n",
            "Estimate Time Left: 00:00:13.747\n",
            "Current Progress: 201/1440\n",
            "Time Spent of 1 Loop: 0.0097s\n",
            "Estimate Time Left: 00:00:12.056\n",
            "Current Progress: 301/1440\n",
            "Time Spent of 1 Loop: 0.01s\n",
            "Estimate Time Left: 00:00:11.358\n",
            "Current Progress: 401/1440\n",
            "Time Spent of 1 Loop: 0.0107s\n",
            "Estimate Time Left: 00:00:11.141\n",
            "Current Progress: 501/1440\n",
            "Time Spent of 1 Loop: 0.0098s\n",
            "Estimate Time Left: 00:00:9.194\n",
            "Current Progress: 601/1440\n",
            "Time Spent of 1 Loop: 0.0094s\n",
            "Estimate Time Left: 00:00:7.893\n",
            "Current Progress: 701/1440\n",
            "Time Spent of 1 Loop: 0.0094s\n",
            "Estimate Time Left: 00:00:6.927\n",
            "Current Progress: 801/1440\n",
            "Time Spent of 1 Loop: 0.0105s\n",
            "Estimate Time Left: 00:00:6.695\n",
            "Current Progress: 901/1440\n",
            "Time Spent of 1 Loop: 0.0111s\n",
            "Estimate Time Left: 00:00:5.969\n",
            "Current Progress: 1001/1440\n",
            "Time Spent of 1 Loop: 0.0098s\n",
            "Estimate Time Left: 00:00:4.292\n",
            "Current Progress: 1101/1440\n",
            "Time Spent of 1 Loop: 0.0101s\n",
            "Estimate Time Left: 00:00:3.411\n",
            "Current Progress: 1201/1440\n",
            "Time Spent of 1 Loop: 0.0093s\n",
            "Estimate Time Left: 00:00:2.22\n",
            "Current Progress: 1301/1440\n",
            "Time Spent of 1 Loop: 0.0094s\n",
            "Estimate Time Left: 00:00:1.31\n",
            "Current Progress: 1401/1440\n",
            "Time Spent of 1 Loop: 0.01s\n",
            "Estimate Time Left: 00:00:0.388\n",
            "111 prediction finished. The result saved in /content/data/prediction/vgg19/predict_111_l thigh.csv\n",
            "now predict 121\n",
            "train vgg19 model\n",
            "Current Progress: 1/1589\n",
            "Time Spent of 1 Loop: 0.0106s\n",
            "Estimate Time Left: 00:00:16.838\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Piloerection/predict_SingleModel.py\", line 304, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/Piloerection/predict_SingleModel.py\", line 241, in main\n",
            "    prediction_timeLine = predictOnePart(frameFile_List_update, \n",
            "  File \"/content/Piloerection/predict_SingleModel.py\", line 80, in predictOnePart\n",
            "    predict, predict_cla, features = predictImg(file_Path, data_transform, model, device)\n",
            "  File \"/content/Piloerection/predict_SingleModel.py\", line 43, in predictImg\n",
            "    output = torch.squeeze(model(img.to(device))).cpu()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/data/test/upload/\n",
        "!cp /content/drive/MyDrive/Piloerection/testData/test_0804.zip /content/data/test/upload/\n",
        "!unzip -uq '/content/data/test/upload/test_0804.zip' -d '/content/data/test/'\n",
        "\n",
        "!cp /content/drive/MyDrive/Piloerection/trainData/predict_train/0804/predict_train0804.zip /content/data/test/upload/\n",
        "!unzip -uq '/content/data/test/upload/predict_train0804.zip' -d '/content/data/test/'"
      ],
      "metadata": {
        "id": "6n_rebXCNC4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Piloerection/predict_Train.py\\\n",
        "  --label_file_path='/content/data/test/file'\\\n",
        "  --predict_file_path='/content/data/test/pred'\\\n",
        "  --save_path='/content/data/test'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUJlyYIOXzUL",
        "outputId": "153ec3fc-782b-44f0-fd37-2ec5631edf6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of models:7; model list:['vgg16', 'vit_base', 'vgg19', 'vit_large', 'resnet101', 'resnet50', 'AlexNet']\n",
            "now calculate the accuracy of vgg16 model\n",
            "Prediction Accuracy of vgg16, Correct:1025, Wrong:11, Accuracy: 0.9894\n",
            "Prediction Accuracy of vgg16, Correct:1542, Wrong:4, Accuracy: 0.9974\n",
            "Prediction Accuracy of vgg16, Correct:1118, Wrong:3, Accuracy: 0.9973\n",
            "Prediction Accuracy of vgg16, Correct:1041, Wrong:0, Accuracy: 1.0\n",
            "Prediction Accuracy of vgg16, Correct:1027, Wrong:9, Accuracy: 0.9913\n",
            "Prediction Accuracy of vgg16, Correct:1026, Wrong:10, Accuracy: 0.9903\n",
            "Prediction Accuracy of vgg16, Correct:1587, Wrong:2, Accuracy: 0.9987\n",
            "Prediction Accuracy of vgg16, Correct:1439, Wrong:1, Accuracy: 0.9993\n",
            "Prediction Accuracy of vgg16, Correct:1120, Wrong:1, Accuracy: 0.9991\n",
            "Prediction Accuracy of vgg16, Correct:1587, Wrong:2, Accuracy: 0.9987\n",
            "Prediction Accuracy of vgg16, Correct:1545, Wrong:1, Accuracy: 0.9994\n",
            "Prediction Accuracy of vgg16, Correct:1034, Wrong:2, Accuracy: 0.9981\n",
            "model:vgg16, average accuracy:0.9965833333333333\n",
            "now calculate the accuracy of vit_base model\n",
            "Prediction Accuracy of vit_base, Correct:41, Wrong:995, Accuracy: 0.0396\n",
            "Prediction Accuracy of vit_base, Correct:1542, Wrong:4, Accuracy: 0.9974\n",
            "Prediction Accuracy of vit_base, Correct:1118, Wrong:3, Accuracy: 0.9973\n",
            "Prediction Accuracy of vit_base, Correct:1041, Wrong:0, Accuracy: 1.0\n",
            "Prediction Accuracy of vit_base, Correct:4, Wrong:1032, Accuracy: 0.0039\n",
            "Prediction Accuracy of vit_base, Correct:4, Wrong:1032, Accuracy: 0.0039\n",
            "Prediction Accuracy of vit_base, Correct:1579, Wrong:10, Accuracy: 0.9937\n",
            "Prediction Accuracy of vit_base, Correct:6, Wrong:1434, Accuracy: 0.0042\n",
            "Prediction Accuracy of vit_base, Correct:1120, Wrong:1, Accuracy: 0.9991\n",
            "Prediction Accuracy of vit_base, Correct:1586, Wrong:3, Accuracy: 0.9981\n",
            "Prediction Accuracy of vit_base, Correct:9, Wrong:1537, Accuracy: 0.0058\n",
            "Prediction Accuracy of vit_base, Correct:1034, Wrong:2, Accuracy: 0.9981\n",
            "model:vit_base, average accuracy:0.5867583333333334\n",
            "now calculate the accuracy of vgg19 model\n",
            "Prediction Accuracy of vgg19, Correct:1025, Wrong:11, Accuracy: 0.9894\n",
            "Prediction Accuracy of vgg19, Correct:1542, Wrong:4, Accuracy: 0.9974\n",
            "Prediction Accuracy of vgg19, Correct:1118, Wrong:3, Accuracy: 0.9973\n",
            "Prediction Accuracy of vgg19, Correct:1041, Wrong:0, Accuracy: 1.0\n",
            "Prediction Accuracy of vgg19, Correct:1027, Wrong:9, Accuracy: 0.9913\n",
            "Prediction Accuracy of vgg19, Correct:1026, Wrong:10, Accuracy: 0.9903\n",
            "Prediction Accuracy of vgg19, Correct:1587, Wrong:2, Accuracy: 0.9987\n",
            "Prediction Accuracy of vgg19, Correct:1439, Wrong:1, Accuracy: 0.9993\n",
            "Prediction Accuracy of vgg19, Correct:1120, Wrong:1, Accuracy: 0.9991\n",
            "Prediction Accuracy of vgg19, Correct:1587, Wrong:2, Accuracy: 0.9987\n",
            "Prediction Accuracy of vgg19, Correct:1545, Wrong:1, Accuracy: 0.9994\n",
            "Prediction Accuracy of vgg19, Correct:1034, Wrong:2, Accuracy: 0.9981\n",
            "model:vgg19, average accuracy:0.9965833333333333\n",
            "now calculate the accuracy of vit_large model\n",
            "Prediction Accuracy of vit_large, Correct:520, Wrong:516, Accuracy: 0.5019\n",
            "Prediction Accuracy of vit_large, Correct:1542, Wrong:4, Accuracy: 0.9974\n",
            "Prediction Accuracy of vit_large, Correct:1118, Wrong:3, Accuracy: 0.9973\n",
            "Prediction Accuracy of vit_large, Correct:1041, Wrong:0, Accuracy: 1.0\n",
            "Prediction Accuracy of vit_large, Correct:4, Wrong:1032, Accuracy: 0.0039\n",
            "Prediction Accuracy of vit_large, Correct:24, Wrong:1012, Accuracy: 0.0232\n",
            "Prediction Accuracy of vit_large, Correct:1585, Wrong:4, Accuracy: 0.9975\n",
            "Prediction Accuracy of vit_large, Correct:1352, Wrong:88, Accuracy: 0.9389\n",
            "Prediction Accuracy of vit_large, Correct:1120, Wrong:1, Accuracy: 0.9991\n",
            "Prediction Accuracy of vit_large, Correct:1587, Wrong:2, Accuracy: 0.9987\n",
            "Prediction Accuracy of vit_large, Correct:0, Wrong:1546, Accuracy: 0.0\n",
            "Prediction Accuracy of vit_large, Correct:1034, Wrong:2, Accuracy: 0.9981\n",
            "model:vit_large, average accuracy:0.7046666666666668\n",
            "now calculate the accuracy of resnet101 model\n",
            "Prediction Accuracy of resnet101, Correct:257, Wrong:779, Accuracy: 0.2481\n",
            "Prediction Accuracy of resnet101, Correct:454, Wrong:1092, Accuracy: 0.2937\n",
            "Prediction Accuracy of resnet101, Correct:1118, Wrong:3, Accuracy: 0.9973\n",
            "Prediction Accuracy of resnet101, Correct:1041, Wrong:0, Accuracy: 1.0\n",
            "Prediction Accuracy of resnet101, Correct:4, Wrong:1032, Accuracy: 0.0039\n",
            "Prediction Accuracy of resnet101, Correct:4, Wrong:1032, Accuracy: 0.0039\n",
            "Prediction Accuracy of resnet101, Correct:166, Wrong:1423, Accuracy: 0.1045\n",
            "Prediction Accuracy of resnet101, Correct:1, Wrong:1439, Accuracy: 0.0007\n",
            "Prediction Accuracy of resnet101, Correct:998, Wrong:123, Accuracy: 0.8903\n",
            "Prediction Accuracy of resnet101, Correct:10, Wrong:1579, Accuracy: 0.0063\n",
            "Prediction Accuracy of resnet101, Correct:0, Wrong:1546, Accuracy: 0.0\n",
            "Prediction Accuracy of resnet101, Correct:1034, Wrong:2, Accuracy: 0.9981\n",
            "model:resnet101, average accuracy:0.37889999999999996\n",
            "now calculate the accuracy of resnet50 model\n",
            "Prediction Accuracy of resnet50, Correct:187, Wrong:849, Accuracy: 0.1805\n",
            "Prediction Accuracy of resnet50, Correct:1441, Wrong:105, Accuracy: 0.9321\n",
            "Prediction Accuracy of resnet50, Correct:1117, Wrong:4, Accuracy: 0.9964\n",
            "Prediction Accuracy of resnet50, Correct:1041, Wrong:0, Accuracy: 1.0\n",
            "Prediction Accuracy of resnet50, Correct:5, Wrong:1031, Accuracy: 0.0048\n",
            "Prediction Accuracy of resnet50, Correct:4, Wrong:1032, Accuracy: 0.0039\n",
            "Prediction Accuracy of resnet50, Correct:701, Wrong:888, Accuracy: 0.4412\n",
            "Prediction Accuracy of resnet50, Correct:1, Wrong:1439, Accuracy: 0.0007\n",
            "Prediction Accuracy of resnet50, Correct:1118, Wrong:3, Accuracy: 0.9973\n",
            "Prediction Accuracy of resnet50, Correct:220, Wrong:1369, Accuracy: 0.1385\n",
            "Prediction Accuracy of resnet50, Correct:0, Wrong:1546, Accuracy: 0.0\n",
            "Prediction Accuracy of resnet50, Correct:1034, Wrong:2, Accuracy: 0.9981\n",
            "model:resnet50, average accuracy:0.47445833333333326\n",
            "now calculate the accuracy of AlexNet model\n",
            "Prediction Accuracy of AlexNet, Correct:329, Wrong:707, Accuracy: 0.3176\n",
            "Prediction Accuracy of AlexNet, Correct:1542, Wrong:4, Accuracy: 0.9974\n",
            "Prediction Accuracy of AlexNet, Correct:1117, Wrong:4, Accuracy: 0.9964\n",
            "Prediction Accuracy of AlexNet, Correct:1041, Wrong:0, Accuracy: 1.0\n",
            "Prediction Accuracy of AlexNet, Correct:4, Wrong:1032, Accuracy: 0.0039\n",
            "Prediction Accuracy of AlexNet, Correct:4, Wrong:1032, Accuracy: 0.0039\n",
            "Prediction Accuracy of AlexNet, Correct:18, Wrong:1571, Accuracy: 0.0113\n",
            "Prediction Accuracy of AlexNet, Correct:1, Wrong:1439, Accuracy: 0.0007\n",
            "Prediction Accuracy of AlexNet, Correct:1106, Wrong:15, Accuracy: 0.9866\n",
            "Prediction Accuracy of AlexNet, Correct:262, Wrong:1327, Accuracy: 0.1649\n",
            "Prediction Accuracy of AlexNet, Correct:0, Wrong:1546, Accuracy: 0.0\n",
            "Prediction Accuracy of AlexNet, Correct:1034, Wrong:2, Accuracy: 0.9981\n",
            "model:AlexNet, average accuracy:0.45673333333333327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fusion Prediction"
      ],
      "metadata": {
        "id": "mz0fYiE-_xHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copy files to colab local disk\n",
        "!mkdir -p /content/data/test/upload/\n",
        "# test frame images\n",
        "!cp /content/drive/MyDrive/Piloerection/testData/testData_0616.zip /content/data/test/upload/\n",
        "!mkdir -p /content/data/test/frameImage\n",
        "!unzip -uq '/content/data/test/upload/testData_0616.zip' -d '/content/data/test/frameImage'\n",
        "\n",
        "# model weights\n",
        "!mkdir -p /content/data/test/model\n",
        "!mkdir -p /content/data/test/model/weights\n",
        "# AlexNet\n",
        "!cp /content/drive/MyDrive/Piloerection/model/AlexNet/AlexNet-47_0729.pth /content/data/test/model/weights/\n",
        "# ViT Large\n",
        "!cp /content/drive/MyDrive/Piloerection/model/ViT/vit_large-20_0727.pth /content/data/test/model/weights\n",
        "# ViT base\n",
        "!cp /content/drive/MyDrive/Piloerection/model/ViT/vit_base-29_0726.pth /content/data/test/model/weights\n",
        "# VGG19\n",
        "!cp /content/drive/MyDrive/Piloerection/model/vgg/vgg19-0_0731.pth /content/data/test/model/weights/\n",
        "# VGG16\n",
        "!cp /content/drive/MyDrive/Piloerection/model/vgg/vgg16-0_0803.pth /content/data/test/model/weights/\n",
        "# ResNet101\n",
        "!cp /content/drive/MyDrive/Piloerection/model/ResNet/resnet101-43_0803.pth /content/data/test/model/weights/\n",
        "# ResNet50\n",
        "!cp /content/drive/MyDrive/Piloerection/model/ResNet/resnet50-45_0801.pth /content/data/test/model/weights/\n",
        "\n",
        "# copy class indices to Colab local disk\n",
        "!cp /content/drive/MyDrive/Piloerection/model/class_indices.json /content/data/test/model/\n",
        "# copy models' predict weights to Colab local disk\n",
        "!cp /content/drive/MyDrive/Piloerection/model/model_weights_0805.csv /content/data/test/model/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0K6tpxsx1Ez",
        "outputId": "ca67bd79-d6ee-4c3b-a320-543f9a0089a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "warning [/content/data/test/upload/testData_0616.zip]:  76 extra bytes at beginning or within zipfile\n",
            "  (attempting to process anyway)\n",
            "error [/content/data/test/upload/testData_0616.zip]:  reported length of central directory is\n",
            "  -76 bytes too long (Atari STZip zipfile?  J.H.Holm ZIPSPLIT 1.1\n",
            "  zipfile?).  Compensating...\n",
            "error:  expected central file header signature not found (file #132373).\n",
            "  (please check that you have transferred or created the zipfile in the\n",
            "  appropriate BINARY mode and that you have compiled UnZip properly)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Piloerection/fusion_predict3.py\\\n",
        "  --data_path='/content/data/test/frameImage/testData_0616'\\\n",
        "  --cal_acc='False'\\\n",
        "  --models_predict_weights='/content/data/test/model/model_weights_0805.csv'\\\n",
        "  --save_path='/content/data/test/prediction'\\\n",
        "  --num_classes=3\\\n",
        "  --models_weights_path='/content/data/test/model/weights'\\\n",
        "  --class_indices='/content/data/test/model/class_indices.json'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkQghSQnonK6",
        "outputId": "96f813fd-096b-42b2-9bad-630c356ffaf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "now predict .ipynb_checkpoints\n",
            ".ipynb_checkpoints prediction finished. The results saved in /content/data/test/prediction\n",
            "now predict 203\n",
            "Current Progress: 1/2205\n",
            "Time Spent of 1 Loop: 7.8927s\n",
            "Estimate Time Left: 04:289:55.412\n",
            "Current Progress: 501/2205\n",
            "Time Spent of 1 Loop: 0.0887s\n",
            "Estimate Time Left: 00:02:31.155\n",
            "Current Progress: 1001/2205\n",
            "Time Spent of 1 Loop: 0.0841s\n",
            "Estimate Time Left: 00:01:41.257\n",
            "Current Progress: 1501/2205\n",
            "Time Spent of 1 Loop: 0.0872s\n",
            "Estimate Time Left: 00:01:1.42\n",
            "Current Progress: 2001/2205\n",
            "Time Spent of 1 Loop: 0.0894s\n",
            "Estimate Time Left: 00:00:18.231\n",
            "203 prediction finished. The results saved in /content/data/test/prediction\n",
            "now predict 208_6\n",
            "Current Progress: 1/1687\n",
            "Time Spent of 1 Loop: 0.1015s\n",
            "Estimate Time Left: 00:02:51.126\n",
            "Current Progress: 501/1687\n",
            "Time Spent of 1 Loop: 0.0894s\n",
            "Estimate Time Left: 00:01:46.061\n",
            "Current Progress: 1001/1687\n",
            "Time Spent of 1 Loop: 0.0822s\n",
            "Estimate Time Left: 00:00:56.377\n",
            "Current Progress: 1501/1687\n",
            "Time Spent of 1 Loop: 0.118s\n",
            "Estimate Time Left: 00:00:21.947\n",
            "Current Progress: 1/1687\n",
            "Time Spent of 1 Loop: 0.1s\n",
            "Estimate Time Left: 00:02:48.629\n",
            "Current Progress: 501/1687\n",
            "Time Spent of 1 Loop: 0.0936s\n",
            "Estimate Time Left: 00:01:51.03\n",
            "Current Progress: 1001/1687\n",
            "Time Spent of 1 Loop: 0.0956s\n",
            "Estimate Time Left: 00:01:5.614\n",
            "Current Progress: 1501/1687\n",
            "Time Spent of 1 Loop: 0.0921s\n",
            "Estimate Time Left: 00:00:17.14\n",
            "Current Progress: 1/1687\n",
            "Time Spent of 1 Loop: 0.1099s\n",
            "Estimate Time Left: 00:03:5.34\n",
            "Current Progress: 501/1687\n",
            "Time Spent of 1 Loop: 0.0988s\n",
            "Estimate Time Left: 00:01:57.215\n",
            "Current Progress: 1001/1687\n",
            "Time Spent of 1 Loop: 0.0921s\n",
            "Estimate Time Left: 00:01:3.202\n",
            "Current Progress: 1501/1687\n",
            "Time Spent of 1 Loop: 0.0945s\n",
            "Estimate Time Left: 00:00:17.579\n",
            "Current Progress: 1/1687\n",
            "Time Spent of 1 Loop: 0.104s\n",
            "Estimate Time Left: 00:02:55.419\n",
            "Current Progress: 501/1687\n",
            "Time Spent of 1 Loop: 0.095s\n",
            "Estimate Time Left: 00:01:52.711\n",
            "Current Progress: 1001/1687\n",
            "Time Spent of 1 Loop: 0.1247s\n",
            "Estimate Time Left: 00:01:25.512\n",
            "Current Progress: 1501/1687\n",
            "Time Spent of 1 Loop: 0.0889s\n",
            "Estimate Time Left: 00:00:16.544\n",
            "208_6 prediction finished. The results saved in /content/data/test/prediction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.move(\"/content/data/model/AlexNet-40_0706.pth\", \"/content/data/model/weights\")\n",
        "shutil.move(\"/content/data/model/vgg19-0.pth\", \"/content/data/model/weights\")\n",
        "shutil.move(\"/content/data/model/vit_base-49_0620.pth\", \"/content/data/model/weights\")\n",
        "shutil.move(\"/content/data/model/vit_large-49_0706.pth\", \"/content/data/model/weights\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WJwbhYInqHT2",
        "outputId": "98f1122a-cbdd-4899-e028-edd737115b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/data/model/weights/vit_large-49_0706.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove the check_points. dir\n",
        "!rmdir /content/data/test/frameImage/testData_0616/\".ipynb_checkpoints\"\n",
        "#!rmdir /content/data/prediction/vit_large/\".ipynb_checkpoints\"\n",
        "#!rmdir /content/data/prediction/AlexNet/\".ipynb_checkpoints\"\n",
        "#!rmdir /content/data/prediction/vgg19/\".ipynb_checkpoints\""
      ],
      "metadata": {
        "id": "KJ4QAIIc225K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##!rm -rf /content/data/test/frameImage/testData_0616/201_6/*\n",
        "!rm -rf /content/data/test/frameImage/testData_0616/202_6/*\n",
        "##!rm -rf /content/data/test/frameImage/testData_0616/203_6/*\n",
        "##!rm -rf /content/data/test/frameImage/testData_0616/204_6/*\n",
        "##!rm -rf /content/data/test/frameImage/testData_0616/205_6/*\n",
        "##!rm -rf /content/data/test/frameImage/testData_0616/206_6/*\n",
        "!rm -rf /content/data/test/frameImage/testData_0616/207_6/*\n",
        "#!rm -rf /content/data/test/frameImage/testData_0616/208_6/*\n",
        "\n",
        "##!rm -rf /content/data/test/frameImage/testData_0616/201/*\n",
        "##!rm -rf /content/data/test/frameImage/testData_0616/202/*\n",
        "#!rm -rf /content/data/test/testData_0616/203/*\n",
        "#!rm -rf /content/data/test/frameImage/testData_0616/204/*\n",
        "#!rm -rf /content/data/test/frameImage/testData_0616/205/*\n",
        "##!rm -rf /content/data/test/frameImage/testData_0616/206/*\n",
        "##!rm -rf /content/data/test/frameImage/testData_0616/207/*\n",
        "##!rm -rf /content/data/test/frameImage/testData_0616/208/*"
      ],
      "metadata": {
        "id": "2RYM2vT31jDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/data/test/frameImage/testData_0616/203/r\\ thigh/*\n",
        "!rm -rf /content/data/test/frameImage/testData_0616/203/l\\ thigh/*\n",
        "!rm -rf /content/data/test/frameImage/testData_0616/203/dom\\ arm/*"
      ],
      "metadata": {
        "id": "ThHojnCYAUcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/data/test/prediction/fusionPredict_208_6*  /content/drive/MyDrive/Piloerection/prediction_results/0806"
      ],
      "metadata": {
        "id": "K8aM3c7Euc2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check Accuracy"
      ],
      "metadata": {
        "id": "RZFyLBU19hz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp /content/drive/MyDrive/Piloerection/testData/test_0804.zip /content/data/test/upload/\n",
        "\n",
        "!mkdir /content/data/test/testAcc\n",
        "!unzip -uq '/content/data/test/upload/test_0804.zip' -d '/content/data/test/testAcc'"
      ],
      "metadata": {
        "id": "ScPauWMh9fV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Piloerection/fusion_predict3.py\\\n",
        "  --data_path='/content/data/test/testAcc/frameImage'\\\n",
        "  --cal_acc='False'\\\n",
        "  --models_predict_weights='/content/data/test/model/model_weights_0805.csv'\\\n",
        "  --save_path='/content/data/test/testAcc/prediction'\\\n",
        "  --num_classes=3\\\n",
        "  --models_weights_path='/content/data/test/model/weights'\\\n",
        "  --class_indices='/content/data/test/model/class_indices.json'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSJxPr2H9_86",
        "outputId": "21e2e163-7fc0-4eb5-8b38-4f0b63bfdabc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "now predict 117\n",
            "Current Progress: 1/1036\n",
            "Time Spent of 1 Loop: 1.3558s\n",
            "Estimate Time Left: 00:23:23.219\n",
            "Current Progress: 501/1036\n",
            "Time Spent of 1 Loop: 0.0808s\n",
            "Estimate Time Left: 00:00:43.232\n",
            "Current Progress: 1001/1036\n",
            "Time Spent of 1 Loop: 0.0797s\n",
            "Estimate Time Left: 00:00:2.788\n",
            "Current Progress: 1/1036\n",
            "Time Spent of 1 Loop: 0.0903s\n",
            "Estimate Time Left: 00:01:33.409\n",
            "Current Progress: 501/1036\n",
            "Time Spent of 1 Loop: 0.0913s\n",
            "Estimate Time Left: 00:00:48.87\n",
            "Current Progress: 1001/1036\n",
            "Time Spent of 1 Loop: 0.0837s\n",
            "Estimate Time Left: 00:00:2.931\n",
            "Current Progress: 1/1036\n",
            "Time Spent of 1 Loop: 0.0953s\n",
            "Estimate Time Left: 00:01:38.659\n",
            "Current Progress: 501/1036\n",
            "Time Spent of 1 Loop: 0.0814s\n",
            "Estimate Time Left: 00:00:43.55\n",
            "Current Progress: 1001/1036\n",
            "Time Spent of 1 Loop: 0.0922s\n",
            "Estimate Time Left: 00:00:3.227\n",
            "Current Progress: 1/1036\n",
            "Time Spent of 1 Loop: 0.0893s\n",
            "Estimate Time Left: 00:01:32.395\n",
            "Current Progress: 501/1036\n",
            "Time Spent of 1 Loop: 0.0933s\n",
            "Estimate Time Left: 00:00:49.939\n",
            "Current Progress: 1001/1036\n",
            "Time Spent of 1 Loop: 0.0836s\n",
            "Estimate Time Left: 00:00:2.924\n",
            "117 prediction finished. The results saved in /content/data/test/testAcc/prediction\n",
            "now predict 131-converted\n",
            "Current Progress: 1/1041\n",
            "Time Spent of 1 Loop: 0.0948s\n",
            "Estimate Time Left: 00:01:38.578\n",
            "Current Progress: 501/1041\n",
            "Time Spent of 1 Loop: 0.0908s\n",
            "Estimate Time Left: 00:00:49.034\n",
            "Current Progress: 1001/1041\n",
            "Time Spent of 1 Loop: 0.0894s\n",
            "Estimate Time Left: 00:00:3.576\n",
            "131-converted prediction finished. The results saved in /content/data/test/testAcc/prediction\n",
            "now predict 107-converted\n",
            "Current Progress: 1/1121\n",
            "Time Spent of 1 Loop: 0.0943s\n",
            "Estimate Time Left: 00:01:45.577\n",
            "Current Progress: 501/1121\n",
            "Time Spent of 1 Loop: 0.097s\n",
            "Estimate Time Left: 00:01:0.115\n",
            "Current Progress: 1001/1121\n",
            "Time Spent of 1 Loop: 0.0894s\n",
            "Estimate Time Left: 00:00:10.728\n",
            "Current Progress: 1/1121\n",
            "Time Spent of 1 Loop: 0.102s\n",
            "Estimate Time Left: 00:01:54.186\n",
            "Current Progress: 501/1121\n",
            "Time Spent of 1 Loop: 0.0895s\n",
            "Estimate Time Left: 00:00:55.508\n",
            "Current Progress: 1001/1121\n",
            "Time Spent of 1 Loop: 0.1036s\n",
            "Estimate Time Left: 00:00:12.437\n",
            "107-converted prediction finished. The results saved in /content/data/test/testAcc/prediction\n",
            "now predict 111\n",
            "Current Progress: 1/1440\n",
            "Time Spent of 1 Loop: 0.1104s\n",
            "Estimate Time Left: 00:02:38.883\n",
            "Current Progress: 501/1440\n",
            "Time Spent of 1 Loop: 0.0954s\n",
            "Estimate Time Left: 00:01:29.592\n",
            "Current Progress: 1001/1440\n",
            "Time Spent of 1 Loop: 0.0969s\n",
            "Estimate Time Left: 00:00:42.536\n",
            "111 prediction finished. The results saved in /content/data/test/testAcc/prediction\n",
            "now predict 127\n",
            "Current Progress: 1/1546\n",
            "Time Spent of 1 Loop: 0.1214s\n",
            "Estimate Time Left: 00:03:7.578\n",
            "Current Progress: 501/1546\n",
            "Time Spent of 1 Loop: 0.0972s\n",
            "Estimate Time Left: 00:01:41.613\n",
            "Current Progress: 1001/1546\n",
            "Time Spent of 1 Loop: 0.0936s\n",
            "Estimate Time Left: 00:00:51.038\n",
            "Current Progress: 1501/1546\n",
            "Time Spent of 1 Loop: 0.1014s\n",
            "Estimate Time Left: 00:00:4.563\n",
            "Current Progress: 1/1546\n",
            "Time Spent of 1 Loop: 0.1068s\n",
            "Estimate Time Left: 00:02:45.018\n",
            "Current Progress: 501/1546\n",
            "Time Spent of 1 Loop: 0.0966s\n",
            "Estimate Time Left: 00:01:40.939\n",
            "Current Progress: 1001/1546\n",
            "Time Spent of 1 Loop: 0.1007s\n",
            "Estimate Time Left: 00:00:54.876\n",
            "Current Progress: 1501/1546\n",
            "Time Spent of 1 Loop: 0.0977s\n",
            "Estimate Time Left: 00:00:4.397\n",
            "127 prediction finished. The results saved in /content/data/test/testAcc/prediction\n",
            "now predict 121\n",
            "Current Progress: 1/1589\n",
            "Time Spent of 1 Loop: 0.1918s\n",
            "Estimate Time Left: 00:05:4.543\n",
            "Current Progress: 501/1589\n",
            "Time Spent of 1 Loop: 0.1105s\n",
            "Estimate Time Left: 00:02:0.177\n",
            "Current Progress: 1001/1589\n",
            "Time Spent of 1 Loop: 0.114s\n",
            "Estimate Time Left: 00:01:7.058\n",
            "Current Progress: 1501/1589\n",
            "Time Spent of 1 Loop: 2.9488s\n",
            "Estimate Time Left: 00:04:19.495\n",
            "Current Progress: 1/1589\n",
            "Time Spent of 1 Loop: 0.4569s\n",
            "Estimate Time Left: 00:12:5.505\n",
            "Current Progress: 501/1589\n",
            "Time Spent of 1 Loop: 0.1083s\n",
            "Estimate Time Left: 00:01:57.829\n",
            "Current Progress: 1001/1589\n",
            "Time Spent of 1 Loop: 0.1023s\n",
            "Estimate Time Left: 00:01:0.145\n",
            "Current Progress: 1501/1589\n",
            "Time Spent of 1 Loop: 0.1474s\n",
            "Estimate Time Left: 00:00:12.972\n",
            "121 prediction finished. The results saved in /content/data/test/testAcc/prediction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/data/test/testAcc/prediction  /content/drive/MyDrive/Piloerection/prediction_results/"
      ],
      "metadata": {
        "id": "qkWkTtnYE6x7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}