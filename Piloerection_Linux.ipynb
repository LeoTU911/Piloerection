{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "collapsed_sections": [
        "Jm-Zaixlmtpg"
      ],
      "authorship_tag": "ABX9TyMg8kJLXGG5JGuN+pdZlVoM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeoTU911/Piloerection/blob/main/Piloerection_Linux.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. DATA IMPORT\n",
        "\n",
        "  1.1 Import code from github\n",
        "  \n",
        "  1.2 Mount Google drive and copy the video data of Google drive to Colab local disk"
      ],
      "metadata": {
        "id": "GBHAjCv_AA4E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7BJm0X0sA8K",
        "outputId": "fc1ef607-e4a3-426d-edab-fa5681763103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Piloerection'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 57 (delta 21), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (57/57), 37.44 KiB | 982.00 KiB/s, done.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# import code files on Github\n",
        "!git clone https://github.com/LeoTU911/Piloerection\n",
        "\n",
        "# import dataset from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "8_BMt-JtEocu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create local dir to store data\n",
        "# Training dir structure\n",
        "!mkdir -p /content/data/train/\n",
        "!mkdir -p /content/data/train/video/\n",
        "!mkdir -p /content/data/train/video/1-grid_videos\n",
        "!mkdir -p /content/data/train/video/4-grid_videos\n",
        "!mkdir -p /content/data/train/file/\n",
        "!mkdir -p /content/data/train/file/1-grid/\n",
        "!mkdir -p /content/data/train/file/4-grid/\n",
        "\n",
        "# copy\n",
        "!cp /content/drive/MyDrive/Piloerection/video/1-grid_videos/* /content/data/train/video/1-grid_videos\n",
        "!cp /content/drive/MyDrive/Piloerection/video/4-grid_videos/* /content/data/train/video/4-grid_videos\n",
        "!cp /content/drive/MyDrive/Piloerection/file/1-grid/* /content/data/train/file/1-grid/\n",
        "!cp /content/drive/MyDrive/Piloerection/file/4-grid/* /content/data/train/file/4-grid/"
      ],
      "metadata": {
        "id": "ajutN8WyAqx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction"
      ],
      "metadata": {
        "id": "PxTbPM1kEswN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create local dir to store data\n",
        "# prediction dir structure\n",
        "!mkdir -p /content/data/test/\n",
        "!mkdir -p /content/data/test/video/\n",
        "!mkdir -p /content/data/test/video/1-grid_videos\n",
        "!mkdir -p /content/data/test/video/4-grid_videos\n",
        "!mkdir -p /content/data/test/file/\n",
        "!mkdir -p /content/data/test/file/1-grid/\n",
        "!mkdir -p /content/data/test/file/4-grid/\n",
        "\n",
        "# copy\n",
        "!cp /content/drive/MyDrive/Piloerection/video/1-grid_videos/* /content/data/test/video/1-grid_videos\n",
        "!cp /content/drive/MyDrive/Piloerection/video/4-grid_videos/* /content/data/test/video/4-grid_videos\n",
        "!cp /content/drive/MyDrive/Piloerection/file/1-grid/* /content/data/train/test/file/1-grid/\n",
        "!cp /content/drive/MyDrive/Piloerection/file/4-grid/* /content/data/train/test/file/4-grid/"
      ],
      "metadata": {
        "id": "ayUajOXeD4Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. DATA PREPROCESSING PART\n",
        "\n",
        "  2.1 Convert video frame to picture\n",
        "\n",
        "  2.2 Frame image preprocessing: denoising, enhancement, changing image size, classification"
      ],
      "metadata": {
        "id": "XmNGprEdEGtM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "uQk8J2pUFEBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# video to images\n",
        "!python /content/Piloerection/video2Img.py\\\n",
        "  --mode='training'\\\n",
        "  --file_Path='/content/data/train/video/'\n",
        "\n",
        "# images pre-processing\n",
        "!python /content/Piloerection/imgPreprocessing.py\\\n",
        "  --mode='training'\\\n",
        "  --frameFile_Path='/content/data/train/frameImage/'\\\n",
        "  --labelFile_Path='/content/data/train/file/'"
      ],
      "metadata": {
        "id": "t1wY17lFEhuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zip file\n",
        "!zip -r '/content/data/train/\"trainFile.zip\"' '/content/data/train/frameImage/*'"
      ],
      "metadata": {
        "id": "6pVVVOxSLH25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction"
      ],
      "metadata": {
        "id": "_BzArIUKGht1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# video to images\n",
        "!python /content/Piloerection/video2Img.py\\\n",
        "  --mode='prediction'\\\n",
        "  --file_Path='/content/data/test/video/'\n",
        "\n",
        "# images pre-processing\n",
        "!python /content/Piloerection/imgPreprocessing.py\\\n",
        "  --mode='prediction'\\\n",
        "  --frameFile_Path='/content/data/test/frameImage/'"
      ],
      "metadata": {
        "id": "nfiMD-NpGjTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zip file\n",
        "!zip -r '/content/data/test/\"testFile.zip\"' '/content/data/test/frameImage/*'"
      ],
      "metadata": {
        "id": "cg34l6IdLLg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TRAINING PART ###"
      ],
      "metadata": {
        "id": "utcnuhaYtv6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare for training\n",
        "# copy files to Colab local disk\n",
        "#!mkdir -p /content/data/train/upload/\n",
        "#!cp /content/drive/MyDrive/Piloerection/trainData/* /content/data/train/upload/\n",
        "#!mkdir -p /content/data/train/frameImage/\n",
        "#!unzip -uq '/content/data/train/upload/large.zip' -d '/content/data/train/frameImage'\n",
        "#!unzip -uq '/content/data/train/upload/small.zip' -d '/content/data/train/frameImage'\n",
        "#!unzip -uq '/content/data/train/upload/no.zip' -d '/content/data/train/frameImage'"
      ],
      "metadata": {
        "id": "h6iiSO-JwTHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Piloerection/train.py\\\n",
        " --data-path='/content/data/train/frameImage'\\\n",
        " --num_classes=3\\\n",
        " --weights=''\\\n",
        " --epochs=50\\\n",
        " --batch-size=64"
      ],
      "metadata": {
        "id": "9BgRTOPD4pyt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "011a793b-e697-43a7-9a62-032b9760f259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-11 19:40:40.510652: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-11 19:40:41.462107: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "49812 images were found in the dataset.\n",
            "39851 images for training.\n",
            "9961 images for validation.\n",
            "Using 2 dataloader workers every process\n",
            "training head.weight\n",
            "training head.bias\n",
            "[train epoch 0] loss: 0.379, acc: 0.886: 100% 2491/2491 [03:15<00:00, 12.77it/s]\n",
            "[valid epoch 0] loss: 0.342, acc: 0.894: 100% 623/623 [00:49<00:00, 12.68it/s]\n",
            "[train epoch 1] loss: 0.364, acc: 0.890:   4% 103/2491 [00:09<03:34, 11.14it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Piloerection/train.py\", line 146, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/Piloerection/train.py\", line 99, in main\n",
            "    train_loss, train_acc = train_one_epoch(model=model,\n",
            "  File \"/content/Piloerection/utils.py\", line 141, in train_one_epoch\n",
            "    accu_num += torch.eq(pred_classes, labels.to(device)).sum()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model's weights to google drive\n",
        "#!cp /content/weights/model-9.pth /content/drive/MyDrive/Piloerection\n",
        "#!cp /content/class_indices.json /content/drive/MyDrive/Piloerection"
      ],
      "metadata": {
        "id": "_rrejCiZ2-aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PREDICTION PART ###"
      ],
      "metadata": {
        "id": "Jm-Zaixlmtpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare for test\n",
        "# copy files to Colab local disk\n",
        "!mkdir -p /content/data/test/upload/\n",
        "!cp /content/drive/MyDrive/Piloerection/testData/testData.zip /content/data/test/upload/\n",
        "!unzip -uq '/content/data/test/upload/testData.zip' -d '/content/data/test/'\n",
        "\n",
        "# copy trained model weights to Colab local disk\n",
        "!mkdir -p /content/data/model\n",
        "!cp /content/drive/MyDrive/Piloerection/model/model-49.pth /content/data/model/\n",
        "\n",
        "# copy class indices to Colab local disk\n",
        "!cp /content/drive/MyDrive/Piloerection/class_indices.json /content/data/"
      ],
      "metadata": {
        "id": "gOsnA5-bgNw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Piloerection/predict.py\\\n",
        " --data_path='/content/data/test/frameImage/'\\\n",
        " --label_path='/content/data/test/file'\\\n",
        " --save_path='/content/data/prediction/'\\\n",
        " --weights='/content/data/model/model-49.pth'\\\n",
        " --class_indices='/content/data/class_indices.json'\\\n",
        " --num_classes=3"
      ],
      "metadata": {
        "id": "PNPNSZWumUn9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "685b0f7b-e95f-43da-bea2-8343f4e1de0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Progress: 1/1876\n",
            "Time Spent of 1 Loop: 7.9222s\n",
            "Estimate Time Left: 04:247:34.145\n",
            "Current Progress: 501/1876\n",
            "Time Spent of 1 Loop: 0.0135s\n",
            "Estimate Time Left: 00:00:18.543\n",
            "Current Progress: 1001/1876\n",
            "Time Spent of 1 Loop: 0.0146s\n",
            "Estimate Time Left: 00:00:12.818\n",
            "Current Progress: 1501/1876\n",
            "Time Spent of 1 Loop: 0.014s\n",
            "Estimate Time Left: 00:00:5.253\n",
            "Prediction Accuracy of 070_r thigh, Correct:1876, Wrong:0, Accuracy: 1.0\n",
            "Current Progress: 1/1876\n",
            "Time Spent of 1 Loop: 0.0164s\n",
            "Estimate Time Left: 00:00:30.69\n",
            "Current Progress: 501/1876\n",
            "Time Spent of 1 Loop: 0.0167s\n",
            "Estimate Time Left: 00:00:22.911\n",
            "Current Progress: 1001/1876\n",
            "Time Spent of 1 Loop: 0.0159s\n",
            "Estimate Time Left: 00:00:13.875\n",
            "Current Progress: 1501/1876\n",
            "Time Spent of 1 Loop: 0.02s\n",
            "Estimate Time Left: 00:00:7.519\n",
            "Prediction Accuracy of 070_dom arm, Correct:1875, Wrong:1, Accuracy: 0.9995\n",
            "Current Progress: 1/1876\n",
            "Time Spent of 1 Loop: 0.0158s\n",
            "Estimate Time Left: 00:00:29.695\n",
            "Current Progress: 501/1876\n",
            "Time Spent of 1 Loop: 0.0197s\n",
            "Estimate Time Left: 00:00:27.019\n",
            "Current Progress: 1001/1876\n",
            "Time Spent of 1 Loop: 0.0139s\n",
            "Estimate Time Left: 00:00:12.176\n",
            "Current Progress: 1501/1876\n",
            "Time Spent of 1 Loop: 0.0143s\n",
            "Estimate Time Left: 00:00:5.373\n",
            "Prediction Accuracy of 070_l thigh, Correct:1876, Wrong:0, Accuracy: 1.0\n",
            "Current Progress: 1/1876\n",
            "Time Spent of 1 Loop: 0.0161s\n",
            "Estimate Time Left: 00:00:30.188\n",
            "Current Progress: 501/1876\n",
            "Time Spent of 1 Loop: 0.0154s\n",
            "Estimate Time Left: 00:00:21.155\n",
            "Current Progress: 1001/1876\n",
            "Time Spent of 1 Loop: 0.0223s\n",
            "Estimate Time Left: 00:00:19.53\n",
            "Current Progress: 1501/1876\n",
            "Time Spent of 1 Loop: 0.0149s\n",
            "Estimate Time Left: 00:00:5.579\n",
            "Prediction Accuracy of 070_dom calf, Correct:1876, Wrong:0, Accuracy: 1.0\n",
            "Current Progress: 1/884\n",
            "Time Spent of 1 Loop: 0.0226s\n",
            "Estimate Time Left: 00:00:19.944\n",
            "Current Progress: 501/884\n",
            "Time Spent of 1 Loop: 0.0139s\n",
            "Estimate Time Left: 00:00:5.334\n",
            "Prediction Accuracy of 028, Correct:839, Wrong:45, Accuracy: 0.9491\n",
            "Current Progress: 1/908\n",
            "Time Spent of 1 Loop: 0.0238s\n",
            "Estimate Time Left: 00:00:21.613\n",
            "Current Progress: 501/908\n",
            "Time Spent of 1 Loop: 0.0144s\n",
            "Estimate Time Left: 00:00:5.867\n",
            "Prediction Accuracy of 024, Correct:893, Wrong:15, Accuracy: 0.9835\n",
            "Current Progress: 1/865\n",
            "Time Spent of 1 Loop: 0.024s\n",
            "Estimate Time Left: 00:00:20.777\n",
            "Current Progress: 501/865\n",
            "Time Spent of 1 Loop: 0.0143s\n",
            "Estimate Time Left: 00:00:5.212\n",
            "Prediction Accuracy of 033, Correct:857, Wrong:8, Accuracy: 0.9908\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Piloerection/predict.py\", line 227, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/Piloerection/predict.py\", line 204, in main\n",
            "    calAccuracy(predictFile = save_name, LabelFile = labelFile, name = videoFile)\n",
            "  File \"/content/Piloerection/predict.py\", line 113, in calAccuracy\n",
            "    label   = pd.read_csv(LabelFile)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\", line 211, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\", line 331, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\", line 950, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\", line 605, in _read\n",
            "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\", line 1442, in __init__\n",
            "    self._engine = self._make_engine(f, self.engine)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\", line 1735, in _make_engine\n",
            "    self.handles = get_handle(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\", line 856, in get_handle\n",
            "    handle = open(\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/data/test/file/1-grid/.ipynb_checkpoints_.csv'\n"
          ]
        }
      ]
    }
  ]
}